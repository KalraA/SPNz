{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "class SumNode:\n",
    "    def __init__(self, id):\n",
    "        self.id = id;\n",
    "        self.children = []\n",
    "        self.parents = []\n",
    "        self.weights = []\n",
    "        self.rank = 0\n",
    "        self.Trank = 0\n",
    "        \n",
    "class PrdNode:\n",
    "    def __init__(self, id):\n",
    "        self.id = id\n",
    "        self.children = []\n",
    "        self.parents = []\n",
    "        self.rank = 0\n",
    "        self.TRank = 0\n",
    "        \n",
    "class Leaf:\n",
    "    def __init__(self, id, a, b, i):\n",
    "        self.id = id;\n",
    "        self.inp = i;\n",
    "        self.children = []\n",
    "        self.parents = [];\n",
    "        self.weights = [a, b];\n",
    "        self.rank = 1;\n",
    "        self.TRank = 0;\n",
    "        \n",
    "class SPN:\n",
    "    def __init__(self, f):\n",
    "        self.loss = None\n",
    "        self.optimizer = None\n",
    "        self.w_nodes, self.w_edges = self.split_up_file(f) #get the node and edge strings from file\n",
    "        self.leaf_id, self.prod_id, self.sum_id, self.id_node_dict = self.build_nodes(self.w_nodes) #build node objects\n",
    "        self.add_connections(self.w_edges)\n",
    "        self.rank = self.add_ranks()\n",
    "        self.node_layers = self.create_layers()\n",
    "        self.pos_dict = self.make_pos_dict()\n",
    "        self.leaf_id_order, self.input_layers, self.input_order = self.clean_up_inputs()\n",
    "        self.inputs = None\n",
    "        self.normed_everyhing = None\n",
    "        self.outputs = None\n",
    "        self.sess = None\n",
    "        self.normalizer = None\n",
    "        self.input_placeholders = []\n",
    "        self.variables = []\n",
    "        self.sparse_tensors = []\n",
    "        self.build_graph()\n",
    "    \n",
    "    def start_sess(self):\n",
    "        assert self.sess == None\n",
    "        self.init = tf.initialize_all_variables()\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(self.init)\n",
    "        \n",
    "    def close_sess(self):\n",
    "        assert self.sess != None\n",
    "        self.sess.close()\n",
    "        self.sess = None\n",
    "    \n",
    "    def predict(self, inp):\n",
    "        assert self.sess != None\n",
    "        print self.outputs.eval(session=self.sess, feed_dict = {self.inputs: inp})\n",
    "    \n",
    "    def train(self, data, epochs):\n",
    "        assert self.sess != None\n",
    "        ndata = np.array(data)\n",
    "        loss_his = []\n",
    "        for e in xrange(epochs):\n",
    "            _, loss, preds = self.sess.run([self.optimizer, self.loss, self.outputs], feed_dict={self.inputs: ndata})\n",
    "            loss_his.append(loss)\n",
    "            display.clear_output(wait=True)  \n",
    "            plt.plot(loss_his, 'r')\n",
    "            plt.show()\n",
    "            print loss\n",
    "            print preds\n",
    "    def build_input_matrix(self, leafs):\n",
    "        inds = []\n",
    "        ws = []\n",
    "        s = []\n",
    "        for i in range(len(leafs)):\n",
    "            node = self.id_node_dict[str(leafs[i])]\n",
    "            a = float(random.random()*0.4 + 1.0)\n",
    "            b = float(random.random()*0.4 + 1.0)\n",
    "            inds.append([i, i*2])\n",
    "            inds.append([i, i*2+1])\n",
    "            ws.append(a)\n",
    "            ws.append(b)\n",
    "        s = [len(leafs), len(leafs)*2]\n",
    "        return tf.Variable(ws, dtype=tf.float64), tf.constant(s, dtype=tf.int64), tf.constant(inds, dtype=tf.int64)\n",
    "    \n",
    "    def build_graph(self):\n",
    "        #inputs\n",
    "        given_input = tf.placeholder(dtype=tf.float64, shape=(len(self.input_order)*2, None))\n",
    "        my_ones = tf.constant([[1]]*len(self.input_order)*2, dtype=tf.float64)\n",
    "        self.inputs = given_input\n",
    "        input_w, input_s, input_i = self.build_input_matrix(self.leaf_id_order)\n",
    "        input_splits = []\n",
    "        norm_splits = []\n",
    "        input_mat = tf.SparseTensor(input_i, tf.identity(tf.nn.relu(input_w)), input_s)\n",
    "        inp_comp = tf.sparse_tensor_dense_matmul(input_mat, given_input)\n",
    "        norm_comp = tf.sparse_tensor_dense_matmul(input_mat, my_ones)\n",
    "        j = 0\n",
    "        for il in self.input_layers:\n",
    "            input_splits.append(inp_comp[j:j+il])\n",
    "            norm_splits.append(norm_comp[j:j+il])\n",
    "            j += il\n",
    "        curr = input_splits[0]\n",
    "        norm = norm_splits[0]\n",
    "        #compute layers\n",
    "        L = 1\n",
    "        Vars = []\n",
    "        Inds = []\n",
    "        for n_l in self.node_layers[1:]:\n",
    "            #build vars:\n",
    "            inds = []\n",
    "            ws = []\n",
    "            shape = []\n",
    "            for i in range(len(n_l)-self.input_layers[L]):\n",
    "                for j in range(len(n_l[i].children)):\n",
    "                    a, b = self.pos_dict[n_l[i].children[j]]\n",
    "                    inds.append([i, b])\n",
    "                    if isinstance(n_l[i], SumNode): \n",
    "                        ws.append(random.random()*0.4 + 1.0)\n",
    "                    else:\n",
    "                        ws.append(1.0)\n",
    "            shape = [len(n_l)-self.input_layers[L], len(self.node_layers[L-1])]\n",
    "            W = tf.Variable(ws, dtype=tf.float64)\n",
    "            I = tf.constant(inds, dtype=tf.int64)\n",
    "            S = tf.constant(shape, dtype=tf.int64)\n",
    "            mat = tf.SparseTensor(I, tf.nn.relu(W), S)\n",
    "            if isinstance(n_l[0], SumNode):\n",
    "                norm = tf.concat(0, [tf.sparse_tensor_dense_matmul(mat, norm), norm_splits[L]])\n",
    "                curr = tf.concat(0, [tf.sparse_tensor_dense_matmul(mat, curr), input_splits[L]])\n",
    "            else:\n",
    "                curr = tf.exp(tf.sparse_tensor_dense_matmul(mat, tf.log(curr)))\n",
    "                norm = tf.exp(tf.sparse_tensor_dense_matmul(mat, tf.log(norm)))\n",
    "            L += 1\n",
    "            self.variables.append(W)\n",
    "            self.sparse_tensors.append(mat)\n",
    "        self.outputs = tf.add(curr, 0.0001)\n",
    "        self.normalizer = norm\n",
    "        norm_val = norm[0][0]\n",
    "        #self.normed_everything = tf.div(self.outputs, norm_val)\n",
    "        self.loss = -tf.reduce_mean(tf.log(self.outputs))\n",
    "        self.optimizer = tf.train.AdamOptimizer().minimize(self.loss)\n",
    "    \n",
    "    def get_norm(self):\n",
    "        print self.normalizer.eval(session=self.sess)\n",
    "    \n",
    "    def clean_up_inputs(self):\n",
    "        input_layers = []\n",
    "        input_order = []\n",
    "        leaf_order = []\n",
    "        for n_lst in self.node_layers:\n",
    "            c = 0\n",
    "            for n in n_lst:\n",
    "                if isinstance(n, Leaf):\n",
    "                    c += 1\n",
    "                    input_order.append(int(n.inp))\n",
    "                    leaf_order.append(n.id)\n",
    "            input_layers.append(c)\n",
    "        return leaf_order, input_layers, input_order\n",
    "    \n",
    "    def make_pos_dict(self):\n",
    "        new_dict = {}\n",
    "        for i in range(len(self.node_layers)):\n",
    "            self.node_layers[i].sort(lambda x, y: 1 if isinstance(x, Leaf) else -1)\n",
    "            for j in range(len(self.node_layers[i])):\n",
    "                new_dict[self.node_layers[i][j].id] = (i, j)\n",
    "        return new_dict\n",
    "    \n",
    "    def create_layers(self):\n",
    "        node_list = [[] for x in range(self.rank)]\n",
    "        for k in self.id_node_dict.keys():\n",
    "            n = self.id_node_dict[k]\n",
    "            node_list[n.TRank].append(n)\n",
    "        return node_list[1:]\n",
    "    \n",
    "    def add_ranks(self):\n",
    "        currs = set(self.leaf_id)\n",
    "        rank = 1\n",
    "        while len(currs) > 0:\n",
    "            prev_currs = currs\n",
    "            new_currs = set()\n",
    "            for s in list(currs):\n",
    "                for p in self.id_node_dict[s].parents:\n",
    "                    new_currs.add(p)\n",
    "                self.id_node_dict[s].rank = rank\n",
    "            currs = new_currs\n",
    "            rank += 1\n",
    "        orank = rank\n",
    "        rank -= 1\n",
    "        currs = prev_currs\n",
    "        while len(currs) > 0:\n",
    "            new_currs = set()\n",
    "            for s in list(currs):\n",
    "                for p in self.id_node_dict[s].children:\n",
    "                    new_currs.add(p)\n",
    "                self.id_node_dict[s].TRank = rank\n",
    "            currs = new_currs\n",
    "            rank -= 1\n",
    "        return orank\n",
    "    \n",
    "    def add_connections(self, edgez):\n",
    "        for e in edgez :\n",
    "            a = e.split(',')\n",
    "            if a[0] == '' or a[1] == '':\n",
    "                continue\n",
    "            self.id_node_dict[a[0]].children.append(a[1])\n",
    "            self.id_node_dict[a[1]].parents.append(a[0])\n",
    "            if len(a) == 3:\n",
    "                self.id_node_dict[a[0]].weights.append(a[2])\n",
    "        \n",
    "    def split_up_file(self, f):\n",
    "        infile = open(f, 'r')\n",
    "        t = 1\n",
    "        lines = []\n",
    "        while t != '':\n",
    "            t = infile.readline()\n",
    "            lines.append(t[:-1])\n",
    "        n = 0\n",
    "        for i in range(len(lines)):\n",
    "            if \"EDGES\" in lines[i]:\n",
    "                n = i;\n",
    "                break;\n",
    "\n",
    "        nodez = lines[1:n]\n",
    "        edgez = lines[n+1:]\n",
    "        return nodez, edgez\n",
    "    \n",
    "    def build_nodes(self, nodez):\n",
    "        big_dict = {}\n",
    "        Leaves = []\n",
    "        Prods = []\n",
    "        Sums = []\n",
    "        for l in nodez:\n",
    "            if 'PRD' in l:\n",
    "                arr = l.split(',')\n",
    "                node = PrdNode(arr[0])\n",
    "                big_dict[arr[0]] = node\n",
    "                Prods.append(arr[0])\n",
    "        #         print 'hi'\n",
    "            elif 'SUM' in l:\n",
    "                arr = l.split(',')\n",
    "                node = SumNode(arr[0])\n",
    "                big_dict[arr[0]] = node\n",
    "                Sums.append(arr[0])\n",
    "            elif 'LEAVE' in l:\n",
    "                arr = l.split(',')\n",
    "                node = Leaf(arr[0], arr[3], arr[4], arr[2])\n",
    "                big_dict[arr[0]] = node\n",
    "                Leaves.append(arr[0])\n",
    "        return Leaves, Prods, Sums, big_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "S = SPN('nltcs.spn.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.31851176e+08]]\n",
      "[[  6.31851176e+08]]\n",
      "[[  1.15223768e+05   1.00000000e-04   2.65467241e+08 ...,   1.00000000e-04\n",
      "    1.00000000e-04   7.25586478e+04]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.6525377723782437"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.start_sess()\n",
    "S.predict([[1], [1]]*len(S.leaf_id))\n",
    "S.get_norm()\n",
    "print S.outputs.eval(session=S.sess, feed_dict={S.inputs: nData.T})\n",
    "S.loss.eval(session=S.sess, feed_dict={S.inputs: nData.T})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEACAYAAAC+gnFaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1189e5e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "[[ nan  nan  nan ...,  nan  nan  nan]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-3be03c0b63ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-78-580b31602e5c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data, epochs)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mloss_his\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mndata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mloss_his\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/PhyrexianDragon/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/PhyrexianDragon/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/PhyrexianDragon/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/PhyrexianDragon/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/PhyrexianDragon/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "S.train(nData.T, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S.close_sess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D = open('nltcs.ts.data', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Data = []\n",
    "i = 'lol'\n",
    "while (i != ''):\n",
    "    i = D.readline()\n",
    "    if i == '':\n",
    "        break;\n",
    "    Data.append((map(lambda x: int(x), i.split(','))*180)[:1574])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Data *= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1574, 16180)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Data[0]), len(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(S.prod_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nData = np.array(Data[:16181])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16180, 1574)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
